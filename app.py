import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
from dateutil.relativedelta import relativedelta

# --- [1. ì„¤ì • ë° ë¦¬ë“œíƒ€ì„ ë§ˆìŠ¤í„°] ---
st.set_page_config(page_title="PÂ·Forecast Stock Manager", layout="wide")

# ìœ ëŸ½ì€ ì„ ì  ë¦¬ë“œíƒ€ì„ 3ê°œì›”ë¡œ ì¼ê´„ ì ìš©
LT_CONFIG = {
    'SE': {'total': 6, 'ship': 3},   # ë…ì¼
    'SRL': {'total': 8, 'ship': 3},  # ì´íƒœë¦¬
    'SP': {'total': 8, 'ship': 3},   # í´ë€ë“œ
    'SH': {'total': 1, 'ship': 0.5}, # ìƒí•´
    'KD': {'total': 2, 'ship': 1},   # ì¤‘êµ­
    'QZ': {'total': 2, 'ship': 1}    # ê´‘ì €ìš°
}

# --- [2. ë°ì´í„° ì •ì œ ìœ í‹¸ë¦¬í‹°] ---
def clean_numeric(series):
    if series.dtype == 'object':
        series = series.astype(str).str.replace(',', '').str.replace('"', '').str.strip()
        series = series.replace(['', 'nan', 'None', 'nan ', ' nan'], np.nan)
    return pd.to_numeric(series, errors='coerce').fillna(0)

def parse_date_smart(series):
    s = series.astype(str).str.replace('.0', '', regex=False).str.strip()
    return pd.to_datetime(s, format='%Y%m%d', errors='coerce')

def smart_load_csv(file):
    for enc in ['cp949', 'utf-8-sig', 'utf-8']:
        try:
            file.seek(0)
            df = pd.read_csv(file, encoding=enc)
            if df.columns.str.contains('Unnamed').sum() > len(df.columns) * 0.4:
                for i in range(1, 6):
                    file.seek(0)
                    df = pd.read_csv(file, skiprows=i, encoding=enc)
                    if not df.columns.str.contains('Unnamed').all(): break
            return df
        except: continue
    return None

# --- [3. ìƒì„¸ íŒì—…ì°½ (í¬ê¸° ë° í•„í„° ê³ ë„í™”)] ---
@st.dialog("í˜„ì¥ë³„ ìƒì„¸ ìˆ˜ì£¼ ë‚´ì—­", width="large")
def show_detail_popup(group_ids, df_bl, cutoff_date):
    st.write(f"ğŸ” ë¶„ì„ ëŒ€ìƒ í’ˆë²ˆ ê·¸ë£¹: {', '.join(group_ids)}")
    code_col = 'ìƒí’ˆì½”ë“œ' if 'ìƒí’ˆì½”ë“œ' in df_bl.columns else df_bl.columns[5]
    
    # í•„í„°: ìˆ˜ì£¼ì”ëŸ‰ > 0 ì´ê³  ì„¤ì •ëœ ì œì™¸ê¸°ê°„ ì´í›„ ë°ì´í„°ë§Œ
    detail = df_bl[df_bl[code_col].astype(str).isin(group_ids)].copy()
    detail = detail[(detail['clean_qty'] > 0) & (detail['dt_clean'] >= cutoff_date)]
    
    if detail.empty:
        st.info("ì¡°ê±´ì— ë§ëŠ” ìˆ˜ì£¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ë‚©ê¸° ê°€ì¥ ë¹ ë¥¸ í˜„ì¥ ìˆœ ì •ë ¬
    st.dataframe(detail.sort_values('dt_clean', ascending=True), use_container_width=True, hide_index=True)

# --- [4. ë©”ì¸ UI ë° íŒŒì¼ ìƒíƒœì°½] ---
st.title("ğŸš€ PÂ·Forecast Stock Manager v4.8")

RECOGNITION = {
    "backlog": {"name": "ìˆ˜ì£¼ì˜ˆì •(Demand)", "keys": ["ìˆ˜ì£¼ì”ëŸ‰", "ì´ì˜ˆìƒìˆ˜ëŸ‰"], "found": False},
    "po": {"name": "êµ¬ë§¤ë°œì£¼(PO)", "keys": ["POì”ëŸ‰", "ë¯¸ì„ ì "], "found": False},
    "stock": {"name": "í˜„ì¬ê³ (Stock)", "keys": ["ì¬ê³ ìˆ˜ëŸ‰", "í˜„ì¬ê³ ì•¡"], "found": False},
    "item": {"name": "í’ˆëª©ì •ë³´(Master)", "keys": ["ìµœì¢…ìƒì‚°ì§€ëª…", "ì´ì „ìƒí’ˆì½”ë“œ"], "found": False},
    "retail": {"name": "ì‹œíŒìŠ¤í™(Retail)", "keys": ["ì¶œì‹œì˜ˆì •", "4ê°œì›”íŒë§¤ëŸ‰"], "found": False}
}

with st.sidebar:
    st.header("âš™ï¸ ë¶„ì„ ì„¤ì •")
    start_date = st.date_input("ê²€í†  ì‹œì (ì¡°íšŒ ì‹œì‘ì¼)", datetime.now())
    freq_opt = st.selectbox("ì§‘ê³„ ë‹¨ìœ„", ["ì£¼ë³„", "ì›”ë³„", "ë¶„ê¸°ë³„", "ë…„ë„ë³„"], index=1)
    exclude_months = st.slider("ê³¼ê±° ìˆ˜ì£¼ ì œì™¸ (Nê°œì›” ê²½ê³¼)", 1, 36, 12)
    cutoff_date = pd.Timestamp(start_date) - relativedelta(months=exclude_months)
    
    st.markdown("---")
    search_query = st.text_input("ğŸ” í’ˆëª…/í’ˆë²ˆ í‚¤ì›Œë“œ ê²€ìƒ‰", "")
    
    st.markdown("---")
    st.subheader("ğŸ“ íŒŒì¼ ë¡œë“œ ìƒíƒœ")
    uploaded_files = st.file_uploader("5ì¢… CSV íŒŒì¼ ì—…ë¡œë“œ", accept_multiple_files=True)

# ë°ì´í„° ë¡œë“œ
data = {}
if uploaded_files:
    for f in uploaded_files:
        df = smart_load_csv(f)
        if df is not None:
            df.columns = [str(c).strip() for c in df.columns]
            cols = "|".join(df.columns)
            for k, v in RECOGNITION.items():
                if any(key in cols for key in v["keys"]):
                    data[k] = df
                    RECOGNITION[k]["found"] = True
                    break

# ì‚¬ì´ë“œë°” ìƒíƒœ í‘œì‹œ (ëŒ€ê¸°ì¤‘ -> ì™„ë£Œ)
with st.sidebar:
    for k, v in RECOGNITION.items():
        if v["found"]: st.success(f"âœ… {v['name']} (ì—…ë¡œë“œ ì™„ë£Œ)")
        else: st.warning(f"â³ {v['name']} (ì—…ë¡œë“œ ëŒ€ê¸°ì¤‘)")

# --- [5. ë©”ì¸ ë¶„ì„ ë¡œì§] ---
if len(data) >= 5:
    with st.spinner('ë°ì´í„°ë¥¼ ì •ë°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...'):
        df_item, df_bl, df_po, df_st, df_retail = data['item'], data['backlog'], data['po'], data['stock'], data['retail']
        
        # 1. ìˆ˜ì£¼/ì¬ê³  ì •ì œ
        bl_code = 'ìƒí’ˆì½”ë“œ' if 'ìƒí’ˆì½”ë“œ' in df_bl.columns else df_bl.columns[5]
        df_bl['clean_qty'] = clean_numeric(df_bl['ìˆ˜ì£¼ì”ëŸ‰'])
        df_bl['dt_clean'] = parse_date_smart(df_bl['ë‚©í’ˆì˜ˆì •ì¼' if 'ë‚©í’ˆì˜ˆì •ì¼' in df_bl.columns else df_bl.columns[24]])
        df_bl = df_bl[df_bl['dt_clean'] >= cutoff_date].copy()

        # 2. PO ë°ì´í„° ì„ ì  LT ë°˜ì˜ ë¡œì§
        po_code = 'í’ˆë²ˆ' if 'í’ˆë²ˆ' in df_po.columns else df_po.columns[12]
        df_po['clean_qty'] = clean_numeric(df_po['POì”ëŸ‰(ë¯¸ì„ ì )'])
        def calculate_arrival(row):
            # ìƒì‚°ì˜ˆì •ì¼ -> ì…ê³ ìš”ì²­ì¼ -> POì¼ì ìˆœ ì¶”ì 
            target_dt = parse_date_smart(pd.Series([row.get('ìƒì‚°ì˜ˆì •ì¼', np.nan)]))[0]
            if pd.isna(target_dt):
                target_dt = parse_date_smart(pd.Series([row.get('ì…ê³ ìš”ì²­ì¼', row.get('POì¼ì', np.nan))]))[0]
            
            site = str(row.get('ìƒì‚°ì§€ëª…', ''))[:2].upper()
            ship_lt = LT_CONFIG.get(site, {'ship': 0})['ship']
            return target_dt + relativedelta(months=int(ship_lt)) if pd.notnull(target_dt) else pd.NaT

        df_po['dt_arrival'] = df_po.apply(calculate_arrival, axis=1)

        st_code = 'í’ˆë²ˆ' if 'í’ˆë²ˆ' in df_st.columns else df_st.columns[7]
        df_st['clean_qty'] = clean_numeric(df_st['ì¬ê³ ìˆ˜ëŸ‰' if 'ì¬ê³ ìˆ˜ëŸ‰' in df_st.columns else df_st.columns[17]])

        # 3. ê¸°ê°„ ì„¤ì • ë° ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
        base_dt = pd.Timestamp(start_date)
        freq_map = {"ì£¼ë³„": "W", "ì›”ë³„": "MS", "ë¶„ê¸°ë³„": "QS", "ë…„ë„ë³„": "YS"}
        date_range = pd.date_range(start=base_dt, periods=13, freq=freq_map[freq_opt])
        time_labels = [d.strftime('%Y-%m-%d' if freq_opt=="ì£¼ë³„" else '%Y-%m') for d in date_range[:12]]

        target_ids = df_bl[df_bl['clean_qty'] > 0][bl_code].unique()
        matrix_rows, alert_list = [], []
        idx_no = 1

        for pid in target_ids:
            pid_s = str(pid)
            item_match = df_item[df_item['ìƒí’ˆì½”ë“œ'].astype(str) == pid_s]
            p_name = str(item_match['ìƒí’ˆëª…'].iloc[0]) if not item_match.empty else "-"
            
            if search_query and (search_query.lower() not in p_name.lower() and search_query.lower() not in pid_s.lower()):
                continue

            # ì—°ê³„ í’ˆë²ˆ ë° ìƒì‚°ì§€ ì •ë³´
            prev = str(item_match['ì´ì „ìƒí’ˆì½”ë“œ'].iloc[0]) if not item_match.empty else ""
            chng = str(item_match['ë³€ê²½ìƒí’ˆì½”ë“œ'].iloc[0]) if not item_match.empty else ""
            prev = prev if prev not in ["nan", "0", "-"] else ""
            chng = chng if chng not in ["nan", "0", "-"] else ""

            def get_site_lt(code):
                if not code: return ""
                m = df_item[df_item['ìƒí’ˆì½”ë“œ'].astype(str) == code]
                if not m.empty:
                    s = str(m['ìµœì¢…ìƒì‚°ì§€ëª…'].iloc[0])[:2]
                    l = LT_CONFIG.get(s.upper(), {'total': 0})['total']
                    return f"({s}/{l}M)"
                return ""

            group = [g for g in [pid_s, prev, chng] if g]
            site_raw = str(item_match['ìµœì¢…ìƒì‚°ì§€ëª…'].iloc[0]) if not item_match.empty else "ETC"
            lt_total = LT_CONFIG.get(site_raw[:2].upper(), {'total': 0})['total']
            is_retail = " ğŸ·ï¸" if any(str(g) in df_retail.iloc[:, 8].astype(str).values for g in group) else ""

            # ì¬ê³  ìˆ˜ì§€ ê³„ì‚°
            main_stk = df_st[df_st[st_code].astype(str).isin(group)]['clean_qty'].sum()
            po_kg = df_po[df_po[po_code].astype(str).isin(group)]['clean_qty'].sum()
            po_m = (po_kg * 1000) / (70 * 1.26)

            overdue_dem = df_bl[(df_bl[bl_code].astype(str).isin(group)) & (df_bl['dt_clean'] < base_dt)]['clean_qty'].sum()
            running_inv = main_stk - overdue_dem
            d_vals, s_vals = {"ë‚©ê¸°ê²½ê³¼": overdue_dem}, {"ë‚©ê¸°ê²½ê³¼": running_inv}

            for i in range(12):
                start, end = date_range[i], date_range[i+1]
                m_dem = df_bl[(df_bl[bl_code].astype(str).isin(group)) & (df_bl['dt_clean'] >= start) & (df_bl['dt_clean'] < end)]['clean_qty'].sum()
                m_po_rows = df_po[(df_po[po_code].astype(str).isin(group)) & (df_po['dt_arrival'] >= start) & (df_po['dt_arrival'] < end)]
                m_sup = sum([(r['clean_qty'] * 1000) / (70 * 1.26) for _, r in m_po_rows.iterrows()])
                
                running_inv = (running_inv + m_sup) - m_dem
                d_vals[time_labels[i]], s_vals[time_labels[i]] = round(m_dem, 0), round(running_inv, 0)
                
                # ê¸´ê¸‰ ë°œì£¼ ì•ŒëŒ íŒë‹¨
                if running_inv < 0 and start < base_dt + relativedelta(months=lt_total):
                    alert_list.append({"í’ˆëª…": p_name, "í’ˆë²ˆ": pid_s, "ë¶€ì¡±ì‹œì ": time_labels[i], "ë¶€ì¡±ìˆ˜ëŸ‰": round(abs(running_inv), 0)})

            common = {"No": idx_no, "í’ˆëª…": p_name, "ìˆ˜ì£¼í’ˆë²ˆ": pid_s + is_retail, "ë³¸ì‚¬ì¬ê³ ": main_stk, "POì”ëŸ‰(m)": po_m, "ìƒì‚°ì§€": f"{site_raw[:2]}({lt_total}M)", "group": group}
            matrix_rows.append({**common, "êµ¬ë¶„": "ì†Œìš”ëŸ‰", "ì—°ê³„ì •ë³´": f"ì´ì „:{prev} {get_site_lt(prev)}" if prev else "", **d_vals})
            matrix_rows.append({"No": idx_no, "í’ˆëª…": "", "ìˆ˜ì£¼í’ˆë²ˆ": "", "ë³¸ì‚¬ì¬ê³ ": np.nan, "POì”ëŸ‰(m)": np.nan, "ìƒì‚°ì§€": "", "group": group, "êµ¬ë¶„": "ì˜ˆìƒì¬ê³ ", "ì—°ê³„ì •ë³´": f"ë³€ê²½:{chng} {get_site_lt(chng)}" if chng else "", **s_vals})
            idx_no += 1

    # [6. ê¸´ê¸‰ ë°œì£¼ ë²„íŠ¼ ë° ìš”ì•½ í‘œ]
    if alert_list:
        if st.button(f"âš ï¸ ê¸´ê¸‰ ë°œì£¼ ê²€í†  ëŒ€ìƒ ë³´ê¸° ({len(pd.DataFrame(alert_list)['í’ˆë²ˆ'].unique())}ê±´)"):
            st.error("ë¦¬ë“œíƒ€ì„ ì´ë‚´ ì¬ê³  ê³ ê°ˆì´ ì˜ˆìƒë˜ëŠ” í’ˆëª© ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.")
            sum_df = pd.DataFrame(alert_list).drop_duplicates(subset=['í’ˆë²ˆ'], keep='first')
            st.table(sum_df.style.format({"ë¶€ì¡±ìˆ˜ëŸ‰": "{:,.0f}"}))

    if matrix_rows:
        res_df = pd.DataFrame(matrix_rows)
        def style_fn(row):
            g_idx = (row.name // 2)
            bg = '#f5f5f5' if g_idx % 2 == 0 else '#ffffff'
            styles = [f'background-color: {bg}'] * len(row)
            for i, col in enumerate(row.index):
                if col == "êµ¬ë¶„": styles[i] = 'background-color: #e1f5fe; font-weight: bold'
                elif row['êµ¬ë¶„'] == "ì˜ˆìƒì¬ê³ " and (col == "ë‚©ê¸°ê²½ê³¼" or col in time_labels):
                    if isinstance(row[col], (int, float)) and row[col] < 0:
                        styles[i] = 'background-color: #ff4b4b; color: white'
            return styles

        st.subheader(f"ğŸ“Š ìˆ˜ê¸‰ ë¶„ì„ ë§¤íŠ¸ë¦­ìŠ¤ ({freq_opt} í•©ì‚°)")
        # ì†Œìˆ˜ì  ì œê±° ë° ì½¤ë§ˆ í¬ë§·
        fmt_dict = {col: "{:,.0f}" for col in ["ë³¸ì‚¬ì¬ê³ ", "POì”ëŸ‰(m)", "ë‚©ê¸°ê²½ê³¼"] + time_labels}
        st_df = st.dataframe(
            res_df.style.apply(style_fn, axis=1).format(fmt_dict, na_rep=""),
            use_container_width=True, hide_index=True,
            column_order=["No", "í’ˆëª…", "ìˆ˜ì£¼í’ˆë²ˆ", "ë³¸ì‚¬ì¬ê³ ", "POì”ëŸ‰(m)", "ìƒì‚°ì§€", "ì—°ê³„ì •ë³´", "êµ¬ë¶„", "ë‚©ê¸°ê²½ê³¼"] + time_labels,
            on_select="rerun", selection_mode="single-row"
        )
        if st_df.selection.rows:
            s_idx = st_df.selection.rows[0]
            target = res_df.iloc[s_idx if res_df.iloc[s_idx]['ìˆ˜ì£¼í’ˆë²ˆ'] != '' else s_idx-1]
            if st.button(f"ğŸ” {target['ìˆ˜ì£¼í’ˆë²ˆ'].replace('ğŸ·ï¸','')} ìƒì„¸ ë³´ê¸°"):
                show_detail_popup(target['group'], df_bl, cutoff_date)
else:
    st.info("ì‚¬ì´ë“œë°”ì— 5ì¢… íŒŒì¼ì„ ëª¨ë‘ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
