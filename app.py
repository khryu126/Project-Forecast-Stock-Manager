import streamlit as st
import pandas as pd
import pickle
import numpy as np
import re
import os
import ssl
import torch
import torchvision.transforms as T
import cv2
import requests
import base64
from PIL import Image, ImageEnhance, ImageDraw
from io import BytesIO
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.preprocessing import image as k_image
from sklearn.metrics.pairwise import cosine_similarity
from streamlit_image_coordinates import streamlit_image_coordinates

# [0] í™˜ê²½ ì„¤ì • ë° ë³´ì•ˆ ëŒ€ì‘
ssl._create_default_https_context = ssl._create_unverified_context

# --- [1] ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---
def get_direct_url(url):
    """êµ¬ê¸€ ë“œë¼ì´ë¸Œ URL ë³€í™˜"""
    if not url or str(url) == 'nan' or 'drive.google.com' not in url: return url
    if 'file/d/' in url: file_id = url.split('file/d/')[1].split('/')[0]
    elif 'id=' in url: file_id = url.split('id=')[1].split('&')[0]
    else: return url
    return f'https://drive.google.com/uc?export=download&id={file_id}'

def get_image_as_base64(url):
    """êµ¬ê¸€ ë³´ì•ˆ ìš°íšŒ: ì„œë²„ ì¸¡ì—ì„œ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì™€ base64ë¡œ ë³€í™˜"""
    try:
        r = requests.get(get_direct_url(url), timeout=10)
        img_str = base64.b64encode(r.content).decode()
        return f"data:image/png;base64,{img_str}"
    except: return None

def load_csv_smart(target_name):
    """ì¸ì½”ë”© ëŒ€ì‘ CSV ë¡œë“œ"""
    files = os.listdir('.')
    for f in files:
        if f.lower() == target_name.lower():
            for enc in ['utf-8-sig', 'cp949', 'utf-8', 'euc-kr']:
                try: return pd.read_csv(f, encoding=enc)
                except: continue
    return pd.DataFrame()

def get_digits(text):
    return "".join(re.findall(r'\d+', str(text))) if text else ""

# --- [2] ë¦¬ì†ŒìŠ¤ ë¡œë”© (ìºì‹±) ---
@st.cache_resource
def init_resources():
    # ëª¨ë¸ ë¡œë“œ (ResNet50 + DINOv2)
    model_res = ResNet50(weights='imagenet', include_top=False, pooling='avg')
    model_dino = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')
    model_dino.eval()
    
    with open('material_features.pkl', 'rb') as f:
        feature_db = pickle.load(f)
        
    df_path = load_csv_smart('ì´ë¯¸ì§€ê²½ë¡œ.csv')
    df_info = load_csv_smart('í’ˆëª©ì •ë³´.csv')
    df_stock = load_csv_smart('í˜„ì¬ê³ .csv')
    
    # [v2.6 ì´ì‹] ì •ë°€ ì¬ê³  ë§¤ì¹­ ë¡œì§
    agg_stock, stock_date = {}, "í™•ì¸ë¶ˆê°€"
    if not df_stock.empty:
        df_stock['ì¬ê³ ìˆ˜ëŸ‰'] = pd.to_numeric(df_stock['ì¬ê³ ìˆ˜ëŸ‰'].astype(str).str.replace(',', ''), errors='coerce').fillna(0)
        df_stock['í’ˆë²ˆ_KEY'] = df_stock['í’ˆë²ˆ'].astype(str).str.strip().str.upper()
        agg_stock = df_stock.groupby('í’ˆë²ˆ_KEY')['ì¬ê³ ìˆ˜ëŸ‰'].sum().to_dict()
        if 'ì •ì‚°ì¼ì' in df_stock.columns:
            stock_date = str(int(df_stock['ì •ì‚°ì¼ì'].max()))
    
    return model_res, model_dino, feature_db, df_path, df_info, agg_stock, stock_date

res_model, dino_model, feature_db, df_path, df_info, agg_stock, stock_date = init_resources()

# DINOv2 ì „ìš© ë³€í™˜
dino_transform = T.Compose([
    T.Resize(224), T.CenterCrop(224), T.ToTensor(),
    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

@st.cache_data
def get_master_map():
    mapping = {}
    for _, row in df_info.iterrows():
        f = str(row.get('ìƒí’ˆì½”ë“œ', '')).strip()
        n = str(row.get('ìƒí’ˆëª…', '')).strip()
        d = get_digits(f)
        if d: mapping[d] = {'formal': f, 'name': n}
    return mapping

master_map = get_master_map()

# --- [3] ì´ë¯¸ì§€ ê³ ë„í™” ì²˜ë¦¬ ì—”ì§„ ---
def apply_advanced_correction(img, angle, bri, con, shp, sat, temp, exp, hue):
    """ìš”ì²­í•˜ì‹  5ëŒ€ ë³´ì • ë° íšŒì „ ê¸°ëŠ¥"""
    if angle != 0: img = img.rotate(angle, expand=True)
    img = ImageEnhance.Brightness(img).enhance(bri)
    img = ImageEnhance.Contrast(img).enhance(con)
    img = ImageEnhance.Sharpness(img).enhance(shp)
    img = ImageEnhance.Color(img).enhance(sat)
    
    img_np = np.array(img).astype(np.float32)
    img_np *= exp # ë…¸ì¶œ ì¡°ì •
    if temp > 1.0: img_np[:, :, 0] *= temp; img_np[:, :, 2] /= temp # Warm
    elif temp < 1.0: img_np[:, :, 2] *= (2.0-temp); img_np[:, :, 0] /= (2.0-temp) # Cool
    img_np = np.clip(img_np, 0, 255).astype(np.uint8)
    
    if hue != 0:
        hsv = cv2.cvtColor(img_np, cv2.COLOR_RGB2HSV).astype(np.float32)
        hsv[:, :, 0] = (hsv[:, :, 0] + hue) % 180
        img_np = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2RGB)
    return Image.fromarray(img_np)

def four_point_transform(image, pts):
    """LANCZOS4 ê³ í™”ì§ˆ ì›Œí•‘"""
    rect = np.zeros((4, 2), dtype="float32")
    s = pts.sum(axis=1); rect[0] = pts[np.argmin(s)]; rect[2] = pts[np.argmax(s)]
    diff = np.diff(pts, axis=1); rect[1] = pts[np.argmin(diff)]; rect[3] = pts[np.argmax(diff)]
    (tl, tr, br, bl) = rect
    w = max(int(np.sqrt(((br[0]-bl[0])**2)+((br[1]-bl[1])**2))), int(np.sqrt(((tr[0]-tl[0])**2)+((tr[1]-tl[1])**2))))
    h = max(int(np.sqrt(((tr[0]-br[0])**2)+((tr[1]-br[1])**2))), int(np.sqrt(((tl[0]-bl[0])**2)+((tl[1]-bl[1])**2))))
    dst = np.array([[0, 0], [w - 1, 0], [w - 1, h - 1], [0, h - 1]], dtype="float32")
    M = cv2.getPerspectiveTransform(rect, dst)
    return cv2.warpPerspective(image, M, (w, h), flags=cv2.INTER_LANCZOS4)

# --- [4] DecoMatch UI ë ˆì´ì•„ì›ƒ ---
st.set_page_config(layout="wide", page_title="DecoMatch - Schattdecor")

# [âš ï¸ ìˆ˜ì •ì™„ë£Œ] unsafe_allow_html=True ë¡œ ë³€ê²½í•˜ì—¬ TypeError í•´ê²°
st.markdown("""
    <style>
    .main { background-color: #f8f9fa; }
    .stButton>button { background-color: #B67741; color: white; border-radius: 4px; border: none; }
    .stExpander { border: 1px solid #B67741; border-radius: 5px; background-color: white; }
    h1 { color: #B67741; font-family: 'Arial Black', sans-serif; }
    </style>
    """, unsafe_allow_html=True)

col_logo, col_title = st.columns([1, 5])
with col_logo:
    st.image("https://brandfetch.com/schattdecor.com?view=library", width=120)
with col_title:
    st.title("DecoMatch")
    st.caption("Advanced Hybrid Surface Pattern Recognition")

st.sidebar.markdown(f"ğŸ“¦ **Inventory Date:** \n{stock_date}")

if 'points' not in st.session_state: st.session_state['points'] = []
if 'search_done' not in st.session_state: st.session_state['search_done'] = False
if 'refresh_count' not in st.session_state: st.session_state['refresh_count'] = 0

uploaded = st.file_uploader("ğŸ“· Upload Material Image", type=['jpg','png','jpeg'])

if uploaded:
    if 'current_img_name' not in st.session_state or st.session_state['current_img_name'] != uploaded.name:
        st.session_state.update({'points': [], 'search_done': False, 'current_img_name': uploaded.name, 'proc_img': Image.open(uploaded).convert('RGB')})
        st.rerun()

    working_img = st.session_state['proc_img']
    w, h = working_img.size

    # 1. ê³ ê¸‰ ì˜µì…˜ Expander
    with st.expander("ğŸ› ï¸ Advanced Image Correction & Rotation", expanded=False):
        c1, c2, c3 = st.columns(3)
        with c1:
            angle = st.slider("Rotation Angle", 0, 360, 0)
            bri = st.slider("Brightness", 0.5, 2.0, 1.0)
            con = st.slider("Contrast", 0.5, 2.0, 1.0)
        with c2:
            shp = st.slider("Sharpness", 0.0, 3.0, 1.5)
            sat = st.slider("Saturation", 0.0, 2.0, 1.0)
            exp = st.slider("Exposure", 0.5, 2.0, 1.0)
        with c3:
            temp = st.slider("Color Temp", 0.5, 1.5, 1.0)
            hue = st.slider("Hue Shift", 0, 180, 0)
            if st.button("ğŸ”„ Reset Points"): st.session_state['points'] = []; st.rerun()

    # 2. ì˜ì—­ ì§€ì • UI
    scale = st.radio("ğŸ” View Scale:", [0.1, 0.3, 0.5, 0.7, 1.0], index=2, horizontal=True)
    
    col_ui, col_pad = st.columns([1, 2])
    with col_ui:
        source_type = st.radio("Source Type", ['ğŸ“¸ Photo', 'ğŸ’» Digital'], horizontal=True)
        mat_type = st.selectbox("Material Category", ['Normal', 'Wood', 'Glossy', 'Texture', 'Stone'])
        s_mode = st.radio("Search Mode", ["Hybrid(Color+Pattern)", "Pattern Only(B&W)"], horizontal=True)
        if st.button("ğŸ”„ Image Refresh"): st.session_state['refresh_count'] += 1; st.rerun()

    with col_pad:
        d_img = working_img.resize((int(w*scale), int(h*scale)), Image.Resampling.LANCZOS)
        draw = ImageDraw.Draw(d_img)
        for i, p in enumerate(st.session_state['points']):
            px, py = p[0]*scale, p[1]*scale
            draw.ellipse((px-8, py-8, px+8, py+8), fill='#B67741', outline='white', width=2)
            draw.text((px+10, py-10), str(i+1), fill='red')
        
        if len(st.session_state['points']) == 4:
            draw.polygon([tuple((p[0]*scale, p[1]*scale)) for p in st.session_state['points']], outline='#00FF00', width=3)

        coords = streamlit_image_coordinates(d_img, key=f"deco_{st.session_state['refresh_count']}")
        if coords and len(st.session_state['points']) < 4:
            new_p = (coords['x']/scale, coords['y']/scale)
            if not st.session_state['points'] or st.session_state['points'][-1] != new_p:
                st.session_state['points'].append(new_p); st.rerun()

    if len(st.session_state['points']) == 4:
        warped = four_point_transform(np.array(working_img), np.array(st.session_state['points'], dtype="float32"))
        final_img = Image.fromarray(warped)
        final_img = apply_advanced_correction(final_img, angle, bri, con, shp, sat, temp, exp, hue)
        if s_mode == "Pattern Only(B&W)": final_img = final_img.convert("L").convert("RGB")
        
        st.image(final_img, width=300, caption="DecoMatch Analysis Target")
        
        if st.button("ğŸ” Run DecoMatch Search", type="primary", use_container_width=True):
            with st.spinner('Analyzing Texture(60%) & Structure(40%)...'):
                x_res = k_image.img_to_array(final_img.resize((224, 224)))
                q_res = res_model.predict(preprocess_input(np.expand_dims(x_res, axis=0)), verbose=0).flatten()
                
                d_in = dino_transform(final_img).unsqueeze(0)
                with torch.no_grad():
                    q_dino = dino_model(d_in).cpu().numpy().flatten()

                # [v2.6 ì •ë°€ ë§¤ì¹­] strip().upper() ê¸°ë°˜ ì¬ê³  ì—°ë™
                results = []
                for fn, db_vec in feature_db.items():
                    s_res = cosine_similarity([q_res], [db_vec[:2048]])[0][0]
                    s_dino = cosine_similarity([q_dino], [db_vec[2048:]])[0][0]
                    score = (s_res * 0.6) + (s_dino * 0.4)
                    
                    d_key = get_digits(fn)
                    info = master_map.get(d_key, {'formal': fn.split('.')[0], 'name': 'Unknown'})
                    
                    # f_key ìƒì„± ë° ì¬ê³  ì¡°íšŒ
                    f_key = str(info['formal']).strip().upper()
                    qty = agg_stock.get(f_key, 0)
                    
                    url_row = df_path[df_path['ì¶”ì¶œëœ_í’ˆë²ˆ'].apply(get_digits) == d_key]
                    url = url_row['ì¹´ì¹´ì˜¤í†¡_ì „ì†¡ìš©_URL'].values[0] if not url_row.empty else None
                    
                    if url:
                        results.append({'formal': info['formal'], 'name': info['name'], 'score': score, 'url': url, 'stock': qty})

                results.sort(key=lambda x: x['score'], reverse=True)
                st.session_state['search_results'] = results[:15]
                st.session_state['search_done'] = True; st.rerun()

# --- [5] ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (Ranked & Expandable) ---
if st.session_state.get('search_done'):
    st.markdown("---")
    st.subheader("ğŸ† Matching Results (Ranked Top 15)")
    res = st.session_state['search_results']
    cols = st.columns(5)
    for i, item in enumerate(res):
        with cols[i % 5]:
            st.markdown(f"#### Rank {i+1}")
            st.markdown(f"**{item['formal']}**")
            st.caption(f"Similarity: {item['score']:.1%}")
            
            with st.expander("ğŸ–¼ï¸ View Detail", expanded=False):
                b64 = get_image_as_base64(item['url'])
                if b64: st.image(b64, use_container_width=True)
                else: st.warning("Image Load Failed")
                st.write(f"**Name:** {item['name']}")
                if item['stock'] >= 100: st.success(f"Stock: {item['stock']:,}m")
                else: st.info(f"Stock: {item['stock']:,}m")
