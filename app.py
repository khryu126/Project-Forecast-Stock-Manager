import streamlit as st
import pandas as pd
from rapidfuzz import process, utils
from datetime import datetime, timedelta

st.set_page_config(page_title="ì„±ì§€ë¼ë¯¸í… íŠ¹íŒ ë°œì£¼ ê²€í†  ì‹œìŠ¤í…œ", layout="wide")

# --- [ì´ë¯¸ì§€: ë°ì´í„° íë¦„ë„] ---
# 

st.title("ğŸ“¦ íŠ¹íŒ ëª¨ì–‘ì§€ ë°œì£¼ ë° í˜„ì¥ ê´€ë¦¬ ì‹œìŠ¤í…œ")
st.sidebar.header("ë°ì´í„° ì—…ë¡œë“œ")

# 1. íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜
uploaded_files = {
    "ìˆ˜ì£¼": st.sidebar.file_uploader("ìˆ˜ì£¼ì˜ˆì •ë“±ë¡.csv", type="csv"),
    "ì¬ê³ ": st.sidebar.file_uploader("í˜„ì¬ê³ .csv", type="csv"),
    "ì¶œê³ ": st.sidebar.file_uploader("ì¶œê³ ë‚´ì—­.csv", type="csv"),
    "í’ˆëª©": st.sidebar.file_uploader("í’ˆëª©ì •ë³´.csv", type="csv"),
    "ì‹œíŒ": st.sidebar.file_uploader("ì‹œíŒìŠ¤í™ê´€ë¦¬.csv", type="csv"),
    "PO": st.sidebar.file_uploader("PO.csv", type="csv")
}

def load_data(file, skiprows=0):
    if file is not None:
        try:
            return pd.read_csv(file, encoding='cp949', skiprows=skiprows)
        except:
            return pd.read_csv(file, encoding='utf-8', skiprows=skiprows)
    return None

# ë°ì´í„° ë¡œë“œ (ë„ì•ˆ êµ¬ì¡° ë°˜ì˜)
df_expected = load_data(uploaded_files["ìˆ˜ì£¼"], skiprows=1)
df_stock = load_data(uploaded_files["ì¬ê³ "])
df_history = load_data(uploaded_files["ì¶œê³ "])
df_item_info = load_data(uploaded_files["í’ˆëª©"])
df_retail = load_data(uploaded_files["ì‹œíŒ"])
df_po = load_data(uploaded_files["PO"])

if df_expected is not None and df_history is not None:
    tab1, tab2 = st.tabs(["ğŸ“ í˜„ì¥ ëˆ„ë½ ë°©ì§€ ì ê²€", "ğŸ“… ì˜¤ë” ì‹œì  ì˜ˆì¸¡"])

    # --- TAB 1: í˜„ì¥ ëˆ„ë½ ë°©ì§€ ---
    with tab1:
        st.subheader("M/H ë° S/H ì¶œê³  ê¸°ë°˜ ëˆ„ë½ í˜„ì¥ íƒì§€")
        
        # M/H, S/H ê´€ë ¨ í‚¤ì›Œë“œ í•„í„°ë§
        keywords = ['M/H', 'MH', 'ëª¨ë¸í•˜ìš°ìŠ¤', 'S/H', 'SH', 'ìƒ˜í”Œ']
        mh_history = df_history[df_history['í˜„ì¥ëª…'].str.contains('|'.join(keywords), na=False, case=False)]
        
        unique_mh_sites = mh_history['í˜„ì¥ëª…'].unique()
        expected_sites = df_expected['í˜„ì¥ëª…'].unique()
        
        results = []
        for site in unique_mh_sites:
            # ìœ ì‚¬ë„ ë§¤ì¹­ (RapidFuzz í™œìš©)
            match = process.extractOne(site, expected_sites, processor=utils.default_process)
            score = match[1] if match else 0
            match_site = match[0] if match else "ì—†ìŒ"
            
            status = "âœ… ë“±ë¡ë¨" if score > 85 else "âš ï¸ ëˆ„ë½ ì˜ì‹¬"
            results.append({"ì¶œê³  í˜„ì¥ëª…": site, "ë§¤ì¹­ ìˆ˜ì£¼ëª…": match_site, "ìœ ì‚¬ë„": score, "ìƒíƒœ": status})
        
        st.table(pd.DataFrame(results))

    # --- TAB 2: ì˜¤ë” ì‹œì  ì˜ˆì¸¡ (ì¬ê³  ìˆ˜ì§€ ë¶„ì„) ---
    with tab2:
        st.subheader("ëª¨ì–‘ì§€ ë°œì£¼ ê²€í†  ë° ì‹œë®¬ë ˆì´ì…˜")
        
        # 1. í‰ëŸ‰(Basis Weight) ë§¤í•‘ í…Œì´ë¸” ìƒì„± (í’ˆëª©ì •ë³´ ê¸°ì¤€)
        # í‰ëŸ‰ì´ í’ˆëª©ì •ë³´ì— ì—†ì„ ê²½ìš° ê¸°ë³¸ê°’ 70g ê°€ì •
        weight_map = {row['ìƒí’ˆì½”ë“œ']: 70 for _, row in df_item_info.iterrows()} 
        
        # 2. PO ë°ì´í„° kg -> m í™˜ì‚°
        if df_po is not None:
            def convert_to_meters(row):
                item_code = row['í’ˆë²ˆ']
                kg = row['PO ìˆ˜ëŸ‰']
                weight = weight_map.get(item_code, 70)
                # í™˜ì‚° ê³µì‹: m = (kg * 1000) / (í‰ëŸ‰ * 1.26)
                return (kg * 1000) / (weight * 1.26)
            
            df_po['PO_m'] = df_po.apply(convert_to_meters, axis=1)

        # 3. í†µí•© ë¶„ì„ (íŠ¹ì • í’ˆë²ˆ ì„ íƒ ì‹œ ì‹œë‚˜ë¦¬ì˜¤ ë³´ì—¬ì£¼ê¸°)
        target_item = st.selectbox("ë¶„ì„í•  í’ˆë²ˆì„ ì„ íƒí•˜ì„¸ìš”", df_expected['ìƒí’ˆì½”ë“œ'].unique())
        
        curr_stock = df_stock[df_stock['í’ˆë²ˆ'] == target_item]['ì¬ê³ ìˆ˜ëŸ‰'].sum()
        po_stock = df_po[df_po['í’ˆë²ˆ'] == target_item]['PO_m'].sum() if df_po is not None else 0
        
        # íŠ¹íŒ ìˆ˜ìš”(ìˆ˜ì£¼ì”ëŸ‰)
        special_demand = df_expected[df_expected['ìƒí’ˆì½”ë“œ'] == target_item]['ìˆ˜ì£¼ì”ëŸ‰'].replace(',', '', regex=True).astype(float).sum()
        
        # ì‹œíŒ ìˆ˜ìš”(ì‹œíŒìŠ¤í™ê´€ë¦¬)
        retail_row = df_retail[df_retail['í’ˆë²ˆ'] == target_item]
        retail_monthly = (retail_row['4ê°œì›”íŒë§¤ëŸ‰'].values[0] / 4) if not retail_row.empty else 0

        st.metric("í˜„ì¬ ì´ ê°€ìš©ëŸ‰ (í˜„ì¬ê³  + PO)", f"{curr_stock + po_stock:,.0f} m")
        
        # ê°„ë‹¨í•œ ì›”ë³„ ì‹œë®¬ë ˆì´ì…˜ (4ê°œì›” ë¦¬ë“œíƒ€ì„ ê³ ë ¤)
        st.write("### ğŸ“… í–¥í›„ 6ê°œì›” ì¬ê³  íë¦„ ì˜ˆì¸¡ (ë…ì¼ ë¦¬ë“œíƒ€ì„ 4ê°œì›”)")
        
        months = [datetime.now() + timedelta(days=30*i) for i in range(7)]
        sim_data = []
        balance = curr_stock + po_stock
        
        for i, m in enumerate(months):
            if i == 0: continue
            # ë§¤ë‹¬ ì‹œíŒ ìˆ˜ìš” ì°¨ê° + í•´ë‹¹ ì›” ë‚©ê¸°ì¸ íŠ¹íŒ ë¬¼ëŸ‰ ì°¨ê° (ìƒ˜í”Œ ë¡œì§)
            balance -= retail_monthly
            sim_data.append({"ì›”": m.strftime("%Y-%m"), "ì˜ˆìƒì¬ê³ ": balance})
        
        st.line_chart(pd.DataFrame(sim_data).set_index("ì›”"))
        
        if balance < special_demand:
            st.error(f"ğŸš¨ ê²½ê³ : 4ê°œì›” ë‚´ ì¬ê³  ì‡¼íŠ¸ ë°œìƒ ìœ„í—˜! (ë¶€ì¡±ë¶„: {special_demand - balance:,.0f} m)")
            st.warning("ë…ì¼ ìˆ˜ì… ë¦¬ë“œíƒ€ì„ì„ ê³ ë ¤í•˜ì—¬ ì´ë²ˆ ë‹¬ ë‚´ë¡œ ì˜¤ë”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

else:
    st.info("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ëª¨ë“  ì†ŒìŠ¤ íŒŒì¼(.csv)ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")