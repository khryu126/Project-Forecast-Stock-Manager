import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta

# --- [1. ì„¤ì • ë° ë¦¬ë“œíƒ€ìž„ ë§ˆìŠ¤í„°] ---
st.set_page_config(page_title="PÂ·Forecast Stock Manager", layout="wide")

LT_CONFIG = {
    'SE': {'total': 6, 'ship_days': 90},
    'SRL': {'total': 8, 'ship_days': 90},
    'SP': {'total': 8, 'ship_days': 90},
    'SH': {'total': 1, 'ship_days': 30}, # ìƒí•´ 1ê°œì›”
    'KD': {'total': 2, 'ship_days': 30},
    'QZ': {'total': 2, 'ship_days': 30}
}

# --- [2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜] ---
def clean_numeric(series):
    if series.dtype == 'object':
        series = series.astype(str).str.replace(',', '').str.replace('"', '').str.strip()
        series = series.replace(['', 'nan', 'None'], np.nan)
    return pd.to_numeric(series, errors='coerce').fillna(0)

def parse_date_smart(series):
    s = series.astype(str).str.replace('.0', '', regex=False).str.strip()
    return pd.to_datetime(s, format='%Y%m%d', errors='coerce')

def smart_load_csv(file):
    for enc in ['cp949', 'utf-8-sig', 'utf-8']:
        try:
            file.seek(0)
            df = pd.read_csv(file, encoding=enc)
            if df.columns.str.contains('Unnamed').sum() > len(df.columns) * 0.4:
                for i in range(1, 6):
                    file.seek(0)
                    df = pd.read_csv(file, skiprows=i, encoding=enc)
                    if not df.columns.str.contains('Unnamed').all(): break
            return df
        except: continue
    return None

# --- [3. ìƒì„¸ íŒì—…ì°½] ---
@st.dialog("í˜„ìž¥ë³„ ìƒì„¸ ìˆ˜ì£¼ ë‚´ì—­", width="large")
def show_detail_popup(group_ids, df_bl, cutoff_date):
    st.write(f"ðŸ”Ž ë¶„ì„ ëŒ€ìƒ í’ˆë²ˆ ê·¸ë£¹: {', '.join(group_ids)}")
    # ìˆ˜ì£¼ì˜ˆì •ë“±ë¡ Gì—´(index 5) ë˜ëŠ” ì´ë¦„ ê¸°ë°˜
    code_col = 'ìƒí’ˆì½”ë“œ' if 'ìƒí’ˆì½”ë“œ' in df_bl.columns else df_bl.columns[5]
    detail = df_bl[df_bl[code_col].astype(str).isin(group_ids)].copy()
    detail = detail[(detail['clean_qty'] > 0) & (detail['dt_clean'] >= cutoff_date)]
    if detail.empty:
        st.info("ì¡°ê±´ì— ë§žëŠ” ìˆ˜ì£¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    st.dataframe(detail.sort_values('dt_clean', ascending=True), use_container_width=True, hide_index=True)

# --- [4. ë©”ì¸ UI] ---
st.title("ðŸš€ PÂ·Forecast Stock Manager v5.5")

with st.sidebar:
    st.header("âš™ï¸ ë¶„ì„ ì„¤ì •")
    start_date_val = st.date_input("ê²€í†  ì‹œì (ì¡°íšŒ ì‹œìž‘ì¼)", datetime.now())
    freq_opt = st.selectbox("ì§‘ê³„ ë‹¨ìœ„", ["ì£¼ë³„", "ì›”ë³„", "ë¶„ê¸°ë³„", "ë…„ë„ë³„"], index=1)
    exclude_months = st.slider("ê³¼ê±° ìˆ˜ì£¼ ì œì™¸ (Nê°œì›” ê²½ê³¼)", 1, 36, 12)
    cutoff_date = pd.Timestamp(start_date_val) - relativedelta(months=exclude_months)
    st.markdown("---")
    search_query = st.text_input("ðŸ” í’ˆëª…/í’ˆë²ˆ í‚¤ì›Œë“œ ê²€ìƒ‰", "")
    st.markdown("---")
    uploaded_files = st.file_uploader("5ì¢… CSV íŒŒì¼ ì—…ë¡œë“œ", accept_multiple_files=True)

# ë°ì´í„° ì¸ì‹
data = {}
RECOGNITION = {
    "backlog": ["ìˆ˜ì£¼ìž”ëŸ‰", "ì´ì˜ˆìƒìˆ˜ëŸ‰"], "po": ["POìž”ëŸ‰", "ë¯¸ì„ ì "],
    "stock": ["ìž¬ê³ ìˆ˜ëŸ‰", "í˜„ìž¬ê³ ì•¡"], "item": ["ìµœì¢…ìƒì‚°ì§€", "ì´ì „ìƒí’ˆì½”ë“œ"],
    "retail": ["ì¶œì‹œì˜ˆì •", "4ê°œì›”íŒë§¤ëŸ‰"]
}
if uploaded_files:
    for f in uploaded_files:
        df = smart_load_csv(f)
        if df is not None:
            df.columns = [str(c).strip() for c in df.columns]
            cols = "|".join(df.columns)
            for k, v in RECOGNITION.items():
                if any(key in cols for key in v):
                    data[k] = df; break

# --- [5. ë©”ì¸ ë¶„ì„ ë¡œì§] ---
if len(data) >= 5:
    with st.spinner('ì •ë°€ ë°ì´í„° ë§µí•‘ ì¤‘...'):
        df_item, df_bl, df_po, df_st, df_retail = data['item'], data['backlog'], data['po'], data['stock'], data['retail']
        
        today_dt = pd.Timestamp(datetime.now().date())
        base_dt = pd.Timestamp(start_date_val)

        # [í’ˆëª© ë§ˆìŠ¤í„° ì¸ë±ìŠ¤ ë§¤í•‘ - ì‚¬ìš©ìž ì •ë³´ ê¸°ë°˜]
        # Gì—´(6): ìƒí’ˆì½”ë“œ, Mì—´(12): ìµœì¢…ìƒì‚°ì§€, Nì—´(13): ì´ì „ìƒí’ˆì½”ë“œ
        item_code_idx = 6
        item_site_idx = 12
        item_prev_idx = 13
        
        # ë§¤ì¹­ ì‚¬ì „ êµ¬ì¶•
        master_site_map = df_item.set_index(df_item.iloc[:, item_code_idx].astype(str).str.strip()).iloc[:, item_site_idx - item_code_idx - 1].to_dict()
        master_prev_map = df_item.set_index(df_item.iloc[:, item_code_idx].astype(str).str.strip()).iloc[:, item_prev_idx - item_code_idx - 1].to_dict()
        # ë°˜ëŒ€ ë§¤ì¹­ (ì´ì „ì½”ë“œë¡œ í˜„ìž¬ì½”ë“œ ì°¾ê¸°)
        master_next_map = df_item.set_index(df_item.iloc[:, item_prev_idx].astype(str).str.strip()).iloc[:, item_code_idx - item_prev_idx].to_dict()

        # 1. ìˆ˜ì£¼ ë°ì´í„° ì •ì œ (Gì—´ ê¸°ì¤€)
        bl_code_col = df_bl.columns[5] # ë³´í†µ Gì—´
        df_bl['clean_qty'] = clean_numeric(df_bl['ìˆ˜ì£¼ìž”ëŸ‰'])
        df_bl['dt_clean'] = parse_date_smart(df_bl.iloc[:, 24]) # ë³´í†µ Yì—´
        df_bl = df_bl[df_bl['dt_clean'] >= cutoff_date].copy()

        # 2. PO ë°ì´í„° ì •ì œ (Mì—´ ê¸°ì¤€)
        po_code_col = df_po.columns[12] # Mì—´
        df_po['m_qty'] = clean_numeric(df_po['POìž”ëŸ‰(ë¯¸ì„ ì )']) * 11.3378 

        def calc_arrival_v55(row):
            pid = str(row[po_code_col]).strip()
            # ë§ˆìŠ¤í„°ì—ì„œ ìƒì‚°ì§€ ì¡°íšŒ
            site_raw = str(master_site_map.get(pid, 'ETC')).upper()
            lt_config = LT_CONFIG.get(site_raw[:2], {'total': 0, 'ship_days': 0})
            
            # ìƒì‚°ì˜ˆì •ì¼ í™•ì¸
            prod_dt = parse_date_smart(pd.Series([row.get('ìƒì‚°ì˜ˆì •ì¼', np.nan)]))[0]
            if pd.notnull(prod_dt):
                return prod_dt + timedelta(days=int(lt_config['ship_days']))
            else:
                po_dt = parse_date_smart(pd.Series([row.get('POì¼ìž', row.get('ìž…ê³ ìš”ì²­ì¼', np.nan))]))[0]
                if pd.isna(po_dt): po_dt = today_dt
                return po_dt + relativedelta(months=int(lt_config['total']))

        df_po['dt_arrival'] = df_po.apply(calc_arrival_v55, axis=1)

        # 3. í˜„ìž¬ê³  ì •ì œ (Hì—´ ê¸°ì¤€)
        st_code_col = df_st.columns[7] # Hì—´
        df_st['clean_qty'] = clean_numeric(df_st.iloc[:, 17]) # í˜„ìž¬ê³  ìˆ˜ëŸ‰

        # 4. ê¸°ê°„ ì„¤ì • ë° í–‰ë ¬ ë£¨í”„
        freq_map = {"ì£¼ë³„": "W", "ì›”ë³„": "MS", "ë¶„ê¸°ë³„": "QS", "ë…„ë„ë³„": "YS"}
        date_range = pd.date_range(start=base_dt, periods=13, freq=freq_map[freq_opt])
        time_labels = [d.strftime('%Y-%m-%d' if freq_opt=="ì£¼ë³„" else '%Y-%m') for d in date_range[:12]]

        target_ids = df_bl[df_bl['clean_qty'] > 0][bl_code_col].unique()
        matrix_rows, alert_list = [], []
        idx_no = 1

        for pid in target_ids:
            pid_s = str(pid).strip()
            item_match = df_item[df_item.iloc[:, item_code_idx].astype(str).str.strip() == pid_s]
            p_name = str(item_match['ìƒí’ˆëª…'].iloc[0]) if not item_match.empty else "-"
            if search_query and (search_query.lower() not in p_name.lower() and search_query.lower() not in pid_s.lower()): continue

            # ê·¸ë£¹í•‘ (ì´ì „/í˜„ìž¬/ë‹¤ìŒ)
            prev_id = str(master_prev_map.get(pid_s, ""))
            next_id = str(master_next_map.get(pid_s, ""))
            group = list(set([pid_s, prev_id, next_id]))
            group = [g for g in group if g and g not in ["nan", "0", "-"]]

            site_raw = str(master_site_map.get(pid_s, "ETC"))
            lt_total = LT_CONFIG.get(site_raw[:2].upper(), {'total': 0})['total']
            is_retail = " ðŸ·ï¸" if any(str(g) in df_retail.iloc[:, 8].astype(str).values for g in group) else ""

            # ê¸°ì´ˆ ìž¬ê³  ë° PO í•©ì‚°
            main_stk = df_st[df_st[st_code_col].astype(str).str.strip().isin(group)]['clean_qty'].sum()
            gap_po_val = df_po[(df_po[po_code_col].astype(str).str.strip().isin(group)) & (df_po['dt_arrival'] >= today_dt) & (df_po['dt_arrival'] < base_dt)]['m_qty'].sum()
            total_start_stk = main_stk + gap_po_val
            po_total_m = df_po[df_po[po_code_col].astype(str).str.strip().isin(group)]['m_qty'].sum()

            overdue_dem = df_bl[(df_bl[bl_code_col].astype(str).str.strip().isin(group)) & (df_bl['dt_clean'] < base_dt)]['clean_qty'].sum()
            running_inv = total_start_stk - overdue_dem
            
            d_row = {"No": idx_no, "í’ˆëª…": p_name, "ìˆ˜ì£¼í’ˆë²ˆ": pid_s + is_retail, "ë³¸ì‚¬ìž¬ê³ ": total_start_stk, "POìž”ëŸ‰(m)": po_total_m, "ìƒì‚°ì§€": f"{site_raw[:2]}({lt_total}M)", "êµ¬ë¶„": "ì†Œìš”ëŸ‰", "ì—°ê³„ì •ë³´": f"ì´ì „:{prev_id}" if prev_id else "", "ë‚©ê¸°ê²½ê³¼": overdue_dem, "group": group}
            p_row = {"No": idx_no, "í’ˆëª…": "", "ìˆ˜ì£¼í’ˆë²ˆ": "", "ë³¸ì‚¬ìž¬ê³ ": np.nan, "POìž”ëŸ‰(m)": np.nan, "ìƒì‚°ì§€": "", "êµ¬ë¶„": "ìž…ê³ ëŸ‰(PO)", "ì—°ê³„ì •ë³´": "", "ë‚©ê¸°ê²½ê³¼": gap_po_val, "group": group}
            s_row = {"No": idx_no, "í’ˆëª…": "", "ìˆ˜ì£¼í’ˆë²ˆ": "", "ë³¸ì‚¬ìž¬ê³ ": np.nan, "POìž”ëŸ‰(m)": np.nan, "ìƒì‚°ì§€": "", "êµ¬ë¶„": "ì˜ˆìƒìž¬ê³ ", "ì—°ê³„ì •ë³´": f"ë³€ê²½:{next_id}" if next_id else "", "ë‚©ê¸°ê²½ê³¼": running_inv, "group": group}

            for i in range(12):
                start, end = date_range[i], date_range[i+1]
                m_dem = df_bl[(df_bl[bl_code_col].astype(str).str.strip().isin(group)) & (df_bl['dt_clean'] >= start) & (df_bl['dt_clean'] < end)]['clean_qty'].sum()
                m_sup = df_po[(df_po[po_code_col].astype(str).str.strip().isin(group)) & (df_po['dt_arrival'] >= start) & (df_po['dt_arrival'] < end)]['m_qty'].sum()
                running_inv = (running_inv + m_sup) - m_dem
                d_row[time_labels[i]], p_row[time_labels[i]], s_row[time_labels[i]] = m_dem, m_sup, running_inv
                if running_inv < 0 and start < base_dt + relativedelta(months=lt_total):
                    alert_list.append({"í’ˆëª…": p_name, "í’ˆë²ˆ": pid_s, "ë¶€ì¡±ì‹œì ": time_labels[i], "ë¶€ì¡±ìˆ˜ëŸ‰": abs(running_inv)})

            matrix_rows.extend([d_row, p_row, s_row])
            idx_no += 1

    if matrix_rows:
        res_df = pd.DataFrame(matrix_rows)
        num_cols = ["ë³¸ì‚¬ìž¬ê³ ", "POìž”ëŸ‰(m)", "ë‚©ê¸°ê²½ê³¼"] + time_labels
        for c in num_cols: res_df[c] = pd.to_numeric(res_df[c], errors='coerce')

        def style_fn(row):
            g_idx = (row.name // 3)
            bg = '#f9f9f9' if g_idx % 2 == 0 else '#ffffff'
            styles = [f'background-color: {bg}'] * len(row)
            for i, col in enumerate(row.index):
                if col == "êµ¬ë¶„": styles[i] = 'background-color: #e1f5fe; font-weight: bold'
                elif row['êµ¬ë¶„'] == "ì˜ˆìƒìž¬ê³ " and col in num_cols:
                    if row[col] < 0: styles[i] = 'background-color: #ff4b4b; color: white'
            return styles

        st.subheader(f"ðŸ“Š í†µí•© ìˆ˜ê¸‰ ë§¤íŠ¸ë¦­ìŠ¤ ({freq_opt})")
        st.dataframe(
            res_df.style.apply(style_fn, axis=1).format({c: "{:,.0f}" for c in num_cols}, na_rep=""),
            use_container_width=True, hide_index=True,
            column_order=["No", "í’ˆëª…", "ìˆ˜ì£¼í’ˆë²ˆ", "ë³¸ì‚¬ìž¬ê³ ", "POìž”ëŸ‰(m)", "ìƒì‚°ì§€", "ì—°ê³„ì •ë³´", "êµ¬ë¶„", "ë‚©ê¸°ê²½ê³¼"] + time_labels,
            on_select="rerun", selection_mode="single-row"
        )
