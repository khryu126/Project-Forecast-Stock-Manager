import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta

# --- [1. ì„¤ì • ë° ë¦¬ë“œíƒ€ì„ ë§ˆìŠ¤í„°] ---
st.set_page_config(page_title="PÂ·Forecast Stock Manager", layout="wide")

# ë¦¬ë“œíƒ€ì„ ì„¤ì •: SR(0) ë“± ë³€ì¹™ ì½”ë“œ ëŒ€ì‘ì„ ìœ„í•´ 'SR' í‚¤ì›Œë“œ ê¸°ì¤€ ê´€ë¦¬
LT_CONFIG = {
    'SE': {'total': 6, 'ship_days': 90},
    'SR': {'total': 8, 'ship_days': 90},  # SR(0), SRL ëª¨ë‘ í¬í•¨
    'SRL': {'total': 8, 'ship_days': 90},
    'SP': {'total': 8, 'ship_days': 90},
    'SH': {'total': 1, 'ship_days': 30},
    'KD': {'total': 2, 'ship_days': 30},
    'QZ': {'total': 2, 'ship_days': 30}
}

# --- [2. ì§€ëŠ¥í˜• ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜] ---
def clean_numeric(series):
    if series.dtype == 'object':
        # ìˆ«ì, ë§ˆì¹¨í‘œ, ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ì œì™¸í•œ ëª¨ë“  ë¬¸ì ì œê±°
        series = series.astype(str).str.replace(r'[^\d.-]', '', regex=True)
        series = series.replace(['', 'nan', 'None'], np.nan)
    return pd.to_numeric(series, errors='coerce').fillna(0)

def parse_date_smart(series):
    """ë‚ ì§œ í˜•ì‹ì„ ì•ˆì „í•˜ê²Œ ë³€í™˜ (ì˜¤ë¥˜ ì‹œ NaT ë°˜í™˜)"""
    s = series.astype(str).str.replace('.0', '', regex=False).str.strip()
    return pd.to_datetime(s, format='%Y%m%d', errors='coerce')

def find_col_precise(df, keywords, exclude_keywords=None, default_idx=None):
    """
    í‚¤ì›Œë“œë¡œ ì»¬ëŸ¼ëª…ì„ ì°¾ë˜, ì œì™¸ í‚¤ì›Œë“œ(ì˜ˆ: 'ëŒ€í‘œ')ê°€ í¬í•¨ëœ ì—´ì€ í”¼í•¨.
    í’ˆëª©ì •ë³´ íŒŒì¼ì—ì„œ 'ìƒí’ˆì½”ë“œ'ì™€ 'ëŒ€í‘œìƒí’ˆì½”ë“œ'ë¥¼ êµ¬ë¶„í•˜ê¸° ìœ„í•¨.
    """
    for k in keywords:
        for col in df.columns:
            col_upper = str(col).replace(" ", "").upper()
            # ë©”ì¸ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆê³ 
            if k in col_upper:
                # ì œì™¸ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆì§€ ì•Šì•„ì•¼ í•¨
                if exclude_keywords:
                    if any(ex.upper() in col_upper for ex in exclude_keywords):
                        continue
                return col
    # ëª» ì°¾ìœ¼ë©´ ê¸°ë³¸ ì¸ë±ìŠ¤ í™œìš©
    if default_idx is not None and len(df.columns) > default_idx:
        return df.columns[default_idx]
    return None

def smart_load_csv(file):
    """v5.3/v6.3ì—ì„œ ê²€ì¦ëœ ì•ˆì •ì ì¸ ë¡œë”© ë¡œì§"""
    for enc in ['cp949', 'utf-8-sig', 'utf-8']:
        try:
            file.seek(0)
            df = pd.read_csv(file, encoding=enc)
            # Unnamedê°€ ë§ìœ¼ë©´ í—¤ë”ê°€ ë°ì´í„° ì•„ë˜ì— ìˆë‹¤ê³  íŒë‹¨í•˜ì—¬ ìŠ¤í‚µ íƒìƒ‰
            if df.columns.str.contains('Unnamed').sum() > len(df.columns) * 0.3:
                for i in range(1, 20):
                    file.seek(0)
                    df = pd.read_csv(file, skiprows=i, encoding=enc)
                    if not df.columns.str.contains('Unnamed').all(): break
            df.columns = [str(c).strip() for c in df.columns]
            return df
        except: continue
    return None

# --- [3. ìƒì„¸ ìˆ˜ì£¼ íŒì—…] ---
@st.dialog("í˜„ì¥ë³„ ìƒì„¸ ìˆ˜ì£¼ ë‚´ì—­", width="large")
def show_detail_popup(group_ids, df_bl, cutoff_date):
    st.write(f"ğŸ” ë¶„ì„ ëŒ€ìƒ í’ˆë²ˆ ê·¸ë£¹: {', '.join(group_ids)}")
    # ìˆ˜ì£¼ì˜ˆì •ë“±ë¡ íŒŒì¼ì—ì„œ ìƒí’ˆì½”ë“œì™€ ìˆ˜ëŸ‰ ì»¬ëŸ¼ íƒìƒ‰
    code_col = find_col_precise(df_bl, ['ìƒí’ˆì½”ë“œ', 'í’ˆë²ˆ'], default_idx=5)
    qty_col = find_col_precise(df_bl, ['ìˆ˜ì£¼ì”ëŸ‰', 'ì”ëŸ‰'], default_idx=30)
    
    group_upper = [g.upper() for g in group_ids]
    detail = df_bl[df_bl[code_col].astype(str).str.upper().str.strip().isin(group_upper)].copy()
    detail['clean_qty'] = clean_numeric(detail[qty_col])
    
    # ë‚ ì§œ ì»¬ëŸ¼(ë³´í†µ ì¸ë±ìŠ¤ 24) ì•ˆì „í•˜ê²Œ íŒŒì‹±
    date_col_idx = 24
    detail['dt_clean_popup'] = pd.to_datetime(detail.iloc[:, date_col_idx].astype(str).str.replace('.0',''), format='%Y%m%d', errors='coerce')
    detail = detail[(detail['clean_qty'] > 0) & (detail['dt_clean_popup'] >= cutoff_date)]
    
    if detail.empty:
        st.info("ì¡°ê±´ì— ë§ëŠ” ìˆ˜ì£¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    st.dataframe(detail.sort_values('dt_clean_popup', ascending=True), use_container_width=True, hide_index=True)

# --- [4. ë©”ì¸ UI] ---
st.title("ğŸš€ PÂ·Forecast Stock Manager v6.4")

# íŒŒì¼ ì¸ì‹ì„ ìœ„í•œ í•µì‹¬ í‚¤ì›Œë“œ (v5.3 ê¸°ë°˜ ì•ˆì •ì„± ìœ ì§€)
RECOGNITION = {
    "backlog": {"name": "ìˆ˜ì£¼ì˜ˆì •(Demand)", "keys": ["ìˆ˜ì£¼ì”ëŸ‰", "ì´ì˜ˆìƒìˆ˜ëŸ‰"], "found": False},
    "po": {"name": "êµ¬ë§¤ë°œì£¼(PO)", "keys": ["POì”ëŸ‰", "ë¯¸ì„ ì "], "found": False},
    "stock": {"name": "í˜„ì¬ê³ (Stock)", "keys": ["ì¬ê³ ìˆ˜ëŸ‰", "í˜„ì¬ê³ ì•¡"], "found": False},
    "item": {"name": "í’ˆëª©ì •ë³´(Master)", "keys": ["ìµœì¢…ìƒì‚°ì§€ëª…", "ì´ì „ìƒí’ˆì½”ë“œ"], "found": False},
    "retail": {"name": "ì‹œíŒìŠ¤í™(Retail)", "keys": ["ì¶œì‹œì˜ˆì •", "4ê°œì›”íŒë§¤ëŸ‰"], "found": False}
}

with st.sidebar:
    st.header("âš™ï¸ ë¶„ì„ ì„¤ì •")
    # ê¸°ë³¸ ë¶„ì„ ì‹œì : ë‹¤ìŒë‹¬ 1ì¼
    default_start = (datetime.now().replace(day=1) + relativedelta(months=1))
    start_date_val = st.date_input("ê²€í†  ì‹œì (ì¡°íšŒ ì‹œì‘ì¼)", default_start)
    freq_opt = st.selectbox("ì§‘ê³„ ë‹¨ìœ„", ["ì£¼ë³„", "ì›”ë³„", "ë¶„ê¸°ë³„", "ë…„ë„ë³„"], index=1)
    exclude_months = st.slider("ê³¼ê±° ìˆ˜ì£¼ ì œì™¸ (Nê°œì›”)", 1, 36, 12)
    cutoff_date = pd.Timestamp(start_date_val) - relativedelta(months=exclude_months)
    st.markdown("---")
    search_query = st.text_input("ğŸ” í’ˆëª…/í’ˆë²ˆ í‚¤ì›Œë“œ ê²€ìƒ‰", "")
    st.markdown("---")
    st.subheader("ğŸ“ íŒŒì¼ ë¡œë“œ ìƒíƒœ")
    uploaded_files = st.file_uploader("5ì¢… CSV íŒŒì¼ ì—…ë¡œë“œ", accept_multiple_files=True)

# ë°ì´í„° ë¡œë”© ì‹¤í–‰
data = {}
if uploaded_files:
    for f in uploaded_files:
        df = smart_load_csv(f)
        if df is not None:
            cols_text = "|".join(df.columns).upper()
            for k, v in RECOGNITION.items():
                if any(key in cols_text for key in v["keys"]):
                    data[k] = df
                    RECOGNITION[k]["found"] = True
                    break

# ì‚¬ì´ë“œë°” ë¡œë“œ ìƒíƒœ í‘œì‹œ
with st.sidebar:
    for k, v in RECOGNITION.items():
        if v["found"]: st.success(f"âœ… {v['name']}")
        else: st.warning(f"â³ {v['name']}")

# --- [5. ë©”ì¸ ë¶„ì„ ë¡œì§] ---
if len(data) >= 5:
    with st.spinner('ìµœì‹  ë§ˆìŠ¤í„° ì •ë³´ ë°˜ì˜ ë° ìˆ˜ê¸‰ ì‹œë®¬ë ˆì´ì…˜ ì¤‘...'):
        df_item, df_bl, df_po, df_st, df_retail = data['item'], data['backlog'], data['po'], data['stock'], data['retail']
        today_dt = pd.Timestamp(datetime.now().date())
        base_dt = pd.Timestamp(start_date_val)

        # 1. í’ˆëª© ë§ˆìŠ¤í„° ì •ë°€ êµ¬ì¶• (v6.4 í•µì‹¬: ìµœì‹  ìƒì„±ì¼ì ìš°ì„ )
        # 'ëŒ€í‘œìƒí’ˆì½”ë“œ'ë¥¼ í”¼í•´ì„œ 'ìƒí’ˆì½”ë“œ' ì—´ì„ ì •í™•íˆ íƒìƒ‰
        it_code = find_col_precise(df_item, ['ìƒí’ˆì½”ë“œ', 'í’ˆë²ˆ'], exclude_keywords=['ëŒ€í‘œ'], default_idx=6)
        it_site = find_col_precise(df_item, ['ìµœì¢…ìƒì‚°ì§€ëª…', 'ìƒì‚°ì§€'], default_idx=12)
        it_prev = find_col_precise(df_item, ['ì´ì „ìƒí’ˆì½”ë“œ'], default_idx=13)
        it_chng = find_col_precise(df_item, ['ë³€ê²½ìƒí’ˆì½”ë“œ'], default_idx=8)
        it_date = find_col_precise(df_item, ['ìƒì„±ì¼ì'], default_idx=3)
        it_name = find_col_precise(df_item, ['ìƒí’ˆëª…', 'í’ˆëª…'], default_idx=1)

        # ë§ˆìŠ¤í„° ë°ì´í„° ì „ì²˜ë¦¬: ìƒì„±ì¼ì ê¸°ì¤€ ì •ë ¬ í›„ ì¤‘ë³µ ì œê±°
        master_proc = df_item.copy()
        master_proc['clean_date'] = parse_date_smart(master_proc[it_date])
        master_proc['key_u'] = master_proc[it_code].astype(str).str.upper().str.strip()
        # ìƒì„±ì¼ì ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬í•˜ì—¬ ê°€ì¥ ìµœì‹  ë°ì´í„°ê°€ ìœ„ë¡œ ì˜¤ê²Œ í•¨
        master_proc = master_proc.sort_values(by=['key_u', 'clean_date'], ascending=[True, False])
        # ì¤‘ë³µëœ í’ˆë²ˆ ì¤‘ ê°€ì¥ ìµœì‹  ê²ƒ(ì²« ë²ˆì§¸)ë§Œ ë‚¨ê¹€
        master_unique = master_proc.drop_duplicates(subset='key_u', keep='first')

        site_map = master_unique.set_index('key_u')[it_site].to_dict()
        prev_map = master_unique.set_index('key_u')[it_prev].to_dict()
        # ì´ì „ì½”ë“œë¡œ í˜„ì¬ì½”ë“œë¥¼ ì°¾ëŠ” ì—­ë°©í–¥ ë§µ (ì²´ì¸ ì—°ê²°ìš©)
        next_map = master_unique.set_index(master_unique[it_prev].astype(str).str.upper().str.strip())[it_code].to_dict()

        # 2. ê° ì†ŒìŠ¤ ë°ì´í„° ì •ì œ
        # ìˆ˜ì£¼ì˜ˆì •
        bl_code_col = find_col_precise(df_bl, ['ìƒí’ˆì½”ë“œ', 'í’ˆë²ˆ'], default_idx=5)
        bl_qty_col = find_col_precise(df_bl, ['ìˆ˜ì£¼ì”ëŸ‰', 'ì´ì˜ˆìƒìˆ˜ëŸ‰'], default_idx=30)
        bl_date_col = find_col_precise(df_bl, ['ë‚©í’ˆì˜ˆì •ì¼'], default_idx=24)
        df_bl['clean_qty'] = clean_numeric(df_bl[bl_qty_col])
        df_bl['dt_clean'] = parse_date_smart(df_bl[bl_date_col])
        df_bl = df_bl[df_bl['dt_clean'] >= cutoff_date].copy()

        # PO (KG -> M í™˜ì‚°)
        po_code_col = find_col_precise(df_po, ['í’ˆë²ˆ', 'ìƒí’ˆì½”ë“œ'], default_idx=12)
        po_qty_col = find_col_precise(df_po, ['POì”ëŸ‰', 'ë¯¸ì„ ì '], default_idx=19)
        po_site_col = find_col_precise(df_po, ['ìƒì‚°ì§€ëª…', 'ê±°ë˜ì²˜'], default_idx=10)
        po_prod_col = find_col_precise(df_po, ['ìƒì‚°ì˜ˆì •ì¼'], default_idx=28)
        po_date_col = find_col_precise(df_po, ['POì¼ì', 'ë°œì£¼ì¼ì'], default_idx=3)
        df_po['m_qty'] = clean_numeric(df_po[po_qty_col]) * 11.3378 

        # [v6.4] ì§€ëŠ¥í˜• ì…ê³ ì¼ ê³„ì‚° (SR ì¸ì‹ ë° ì‚¬ê°ì§€ëŒ€ ì „ì§„ ë°°ì¹˜)
        def calc_arrival_v64(row):
            pid_u = str(row[po_code_col]).upper().strip()
            # POíŒŒì¼ì— ì—†ìœ¼ë©´ ë§ˆìŠ¤í„° íŒŒì¼(ìµœì‹ ìˆœ ì •ë ¬ë¨)ì—ì„œ ìƒì‚°ì§€ ì¡°íšŒ
            site_v = str(row.get(po_site_col, site_map.get(pid_u, 'ETC'))).upper()
            
            # SR(0), SRL ë“±ì„ ëª¨ë‘ 'SR' í‚¤ì›Œë“œë¡œ í†µí•© ì¸ì‹
            site_k = 'SR' if 'SR' in site_v else site_v[:2]
            lt = LT_CONFIG.get(site_k, LT_CONFIG.get(site_v[:2], {'total': 1, 'ship_days': 30}))
            
            p_dt = parse_date_smart(pd.Series([row.get(po_prod_col, np.nan)]))[0]
            if pd.notnull(p_dt):
                arrival = p_dt + pd.DateOffset(days=int(lt['ship_days']))
            else:
                b_dt = parse_date_smart(pd.Series([row.get(po_date_col, today_dt)]))[0]
                if pd.isna(b_dt): b_dt = today_dt
                arrival = b_dt + pd.DateOffset(months=int(lt['total']))
            
            # [ìˆ˜ì •] ì¡°íšŒ ì‹œì‘ì¼(base_dt) ì´ì „ ë¬¼ëŸ‰ì€ 'ì²« ë¶„ì„ë‹¬' ê°€ìš© ë¬¼ëŸ‰ìœ¼ë¡œ ê°•ì œ ì „ì§„ ë°°ì¹˜
            if pd.isnull(arrival) or arrival < base_dt:
                # ì˜¤ëŠ˜ ì„ ì  ì§€ì‹œ ì‹œ ê°€ì¥ ë¹ ë¥¸ ë„ì°©ì¼ ê³„ì‚°
                arrival = today_dt + pd.DateOffset(days=int(lt['ship_days']))
                # ê·¸ë˜ë„ ì‹œì‘ì¼ë³´ë‹¤ ë¹ ë¥´ë©´ ì‹œì‘ì¼ ë‹¹ì¼ë¡œ ë§ì¶¤
                if arrival < base_dt: arrival = base_dt
            return arrival

        df_po['dt_arrival'] = df_po.apply(calc_arrival_v64, axis=1)

        # ì¬ê³ 
        st_code_col = find_col_precise(df_st, ['í’ˆë²ˆ', 'ìƒí’ˆì½”ë“œ'], default_idx=7)
        st_qty_col = find_col_precise(df_st, ['ì¬ê³ ìˆ˜ëŸ‰', 'í˜„ì¬ê³ '], default_idx=17)
        df_st['clean_qty'] = clean_numeric(df_st[st_qty_col])

        # 3. íƒ€ì„ë¼ì¸ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
        freq_map = {"ì£¼ë³„": "W", "ì›”ë³„": "MS", "ë¶„ê¸°ë³„": "QS", "ë…„ë„ë³„": "YS"}
        date_range = pd.date_range(start=base_dt, periods=13, freq=freq_map[freq_opt])
        time_labels = [d.strftime('%Y-%m-%d' if freq_opt=="ì£¼ë³„" else '%Y-%m') for d in date_range[:12]]

        target_ids = df_bl[df_bl['clean_qty'] > 0][bl_code_col].unique()
        matrix_rows, alert_list = [], []
        idx_no = 1

        for pid in target_ids:
            pid_s = str(pid).strip(); pid_u = pid_s.upper()
            item_match = master_unique[master_unique['key_u'] == pid_u]
            p_name = str(item_match[it_name].iloc[0]) if not item_match.empty else "-"
            
            if search_query and (search_query.lower() not in p_name.lower() and search_query.lower() not in pid_s.lower()):
                continue

            # í’ˆë²ˆ ì—°ê³„ ê·¸ë£¹í•‘ ë° 'NAN' í´ë¦¬ë‹
            def clean_pid_str(v):
                s = str(v).strip().upper()
                return s if s not in ["NAN", "NONE", "0", "-", ""] else ""
            
            p_id = clean_pid_str(prev_map.get(pid_u, ""))
            n_id = clean_pid_str(next_map.get(pid_u, ""))
            group = list(set([pid_u, p_id, n_id])); group = [g for g in group if g]

            # ìƒì‚°ì§€ ë° LT ì •ë³´ (v6.4: SR í¬í•¨ ì—¬ë¶€ë¡œ íŒë³„)
            site_name = str(site_map.get(pid_u, "ETC"))
            site_key = 'SR' if 'SR' in site_name.upper() else site_name[:2].upper()
            lt_total = LT_CONFIG.get(site_key, {'total': 0})['total']
            
            # ì‹œíŒìŠ¤í™ ì—¬ë¶€
            is_retail = " ğŸ·ï¸" if any(str(g).upper() in df_retail.iloc[:, 8].astype(str).str.upper().values for g in group) else ""

            # ê¸°ì´ˆ ì¬ê³  ìˆ˜ì§€ ê³„ì‚°
            main_stk = df_st[df_st[st_code_col].astype(str).str.upper().str.strip().isin(group)]['clean_qty'].sum()
            overdue_dem = df_bl[(df_bl[bl_code_col].astype(str).str.upper().str.strip().isin(group)) & (df_bl['dt_clean'] < base_dt)]['clean_qty'].sum()
            running_inv = main_stk - overdue_dem
            
            # 3í–‰ 1ì„¸íŠ¸ ë°ì´í„° êµ¬ì¡°í™”
            d_row = {"No": idx_no, "í’ˆëª…": p_name, "ìˆ˜ì£¼í’ˆë²ˆ": pid_s + is_retail, "ë³¸ì‚¬ì¬ê³ ": main_stk, "POì”ëŸ‰(m)": df_po[df_po[po_code_col].astype(str).str.upper().str.strip().isin(group)]['m_qty'].sum(), "ìƒì‚°ì§€": f"{site_key}({lt_total}M)", "êµ¬ë¶„": "ì†Œìš”ëŸ‰", "ì—°ê³„ì •ë³´": f"ì´ì „:{p_id}" if p_id else "", "ë‚©ê¸°ê²½ê³¼": overdue_dem, "group": group}
            p_row = {"No": idx_no, "í’ˆëª…": "", "ìˆ˜ì£¼í’ˆë²ˆ": "", "ë³¸ì‚¬ì¬ê³ ": np.nan, "POì”ëŸ‰(m)": np.nan, "ìƒì‚°ì§€": "", "êµ¬ë¶„": "ì…ê³ ëŸ‰(PO)", "ì—°ê³„ì •ë³´": "", "ë‚©ê¸°ê²½ê³¼": 0, "group": group}
            s_row = {"No": idx_no, "í’ˆëª…": "", "ìˆ˜ì£¼í’ˆë²ˆ": "", "ë³¸ì‚¬ì¬ê³ ": np.nan, "POì”ëŸ‰(m)": np.nan, "ìƒì‚°ì§€": "", "êµ¬ë¶„": "ì˜ˆìƒì¬ê³ ", "ì—°ê³„ì •ë³´": f"ë³€ê²½:{n_id}" if n_id else "", "ë‚©ê¸°ê²½ê³¼": running_inv, "group": group}

            for i in range(12):
                start, end = date_range[i], date_range[i+1]
                m_dem = df_bl[(df_bl[bl_code_col].astype(str).str.upper().str.strip().isin(group)) & (df_bl['dt_clean'] >= start) & (df_bl['dt_clean'] < end)]['clean_qty'].sum()
                m_sup = df_po[(df_po[po_code_col].astype(str).str.upper().str.strip().isin(group)) & (df_po['dt_arrival'] >= start) & (df_po['dt_arrival'] < end)]['m_qty'].sum()
                running_inv = (running_inv + m_sup) - m_dem
                
                label = time_labels[i]
                d_row[label], p_row[label], s_row[label] = m_dem, m_sup, running_inv
                
                # ë¦¬ë“œíƒ€ì„ ë‚´ ì¬ê³  ë¶€ì¡± ì‹œ ì•Œë¦¼ ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
                if running_inv < 0 and start < base_dt + pd.DateOffset(months=lt_total):
                    alert_list.append({"í’ˆëª…": p_name, "í’ˆë²ˆ": pid_s, "ë¶€ì¡±ì‹œì ": label, "ë¶€ì¡±ìˆ˜ëŸ‰": abs(running_inv)})

            matrix_rows.extend([d_row, p_row, s_row]); idx_no += 1

    # ê²°ê³¼ ë§¤íŠ¸ë¦­ìŠ¤ ì¶œë ¥
    if matrix_rows:
        res_df = pd.DataFrame(matrix_rows)
        num_cols = ["ë³¸ì‚¬ì¬ê³ ", "POì”ëŸ‰(m)", "ë‚©ê¸°ê²½ê³¼"] + time_labels
        for c in num_cols: res_df[c] = pd.to_numeric(res_df[c], errors='coerce')

        def style_fn(row):
            g_idx = (row.name // 3); bg = '#f9f9f9' if g_idx % 2 == 0 else '#ffffff'
            styles = [f'background-color: {bg}'] * len(row)
            for i, col in enumerate(row.index):
                if col == "êµ¬ë¶„": styles[i] = 'background-color: #e1f5fe; font-weight: bold'
                elif row['êµ¬ë¶„'] == "ì˜ˆìƒì¬ê³ " and col in num_cols:
                    if row[col] < 0: styles[i] = 'background-color: #ff4b4b; color: white'
            return styles

        st.subheader(f"ğŸ“Š í†µí•© ìˆ˜ê¸‰ ì‹œë®¬ë ˆì´ì…˜ ({freq_opt})")
        st_df = st.dataframe(
            res_df.style.apply(style_fn, axis=1).format({c: "{:,.0f}" for c in num_cols}, na_rep=""),
            use_container_width=True, hide_index=True,
            column_order=["No", "í’ˆëª…", "ìˆ˜ì£¼í’ˆë²ˆ", "ë³¸ì‚¬ì¬ê³ ", "POì”ëŸ‰(m)", "ìƒì‚°ì§€", "ì—°ê³„ì •ë³´", "êµ¬ë¶„", "ë‚©ê¸°ê²½ê³¼"] + time_labels,
            on_select="rerun", selection_mode="single-row"
        )
        
        # ì„ íƒëœ í’ˆë²ˆ ìƒì„¸ ìˆ˜ì£¼ ë‚´ì—­ íŒì—… ì—°ë™
        if st_df.selection.rows:
            s_idx = st_df.selection.rows[0]
            target = res_df.iloc[s_idx - (s_idx % 3)]
            if st.button(f"ğŸ” {str(target['ìˆ˜ì£¼í’ˆë²ˆ']).replace('ğŸ·ï¸','').strip()} ìƒì„¸ ë³´ê¸°"):
                show_detail_popup(target['group'], df_bl, cutoff_date)
else:
    st.info("ì‚¬ì´ë“œë°”ì— 5ì¢… íŒŒì¼ì„ ëª¨ë‘ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
