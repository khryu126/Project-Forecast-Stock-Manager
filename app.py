import streamlit as st
import pandas as pd
import pickle
import numpy as np
import re
import os
import ssl
import torch
import torchvision.transforms as T
import cv2
import requests
import base64
from PIL import Image, ImageEnhance, ImageDraw
from io import BytesIO
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.preprocessing import image as k_image
from sklearn.metrics.pairwise import cosine_similarity
from streamlit_image_coordinates import streamlit_image_coordinates

# [0] í™˜ê²½ ì„¤ì • ë° ë³´ì•ˆ ëŒ€ì‘ (DINOv2 ë° ì´ë¯¸ì§€ ë¡œë”© ì•ˆì •í™”)
ssl._create_default_https_context = ssl._create_unverified_context

# --- [1] ìœ í‹¸ë¦¬í‹° ë° ë°ì´í„° ë¡œë“œ ë¡œì§ ---
def get_direct_url(url):
    """êµ¬ê¸€ ë“œë¼ì´ë¸Œ URL ë³€í™˜"""
    if not url or str(url) == 'nan' or 'drive.google.com' not in url: return url
    if 'file/d/' in url: file_id = url.split('file/d/')[1].split('/')[0]
    elif 'id=' in url: file_id = url.split('id=')[1].split('&')[0]
    else: return url
    return f'https://drive.google.com/uc?export=download&id={file_id}'

def get_image_as_base64(url):
    """êµ¬ê¸€ ë³´ì•ˆ ìš°íšŒ ë° ì—‘ë°• ë°©ì§€ (Base64 Proxy)"""
    try:
        r = requests.get(get_direct_url(url), timeout=10)
        img_str = base64.b64encode(r.content).decode()
        return f"data:image/png;base64,{img_str}"
    except: return None

def load_csv_smart(target_name):
    """4ê°€ì§€ ì¸ì½”ë”© ìë™ ì‹œë„ë¡œ í•œê¸€ ê¹¨ì§ ë°©ì§€"""
    files = os.listdir('.')
    for f in files:
        if f.lower() == target_name.lower():
            for enc in ['utf-8-sig', 'cp949', 'utf-8', 'euc-kr']:
                try: return pd.read_csv(f, encoding=enc)
                except: continue
    return pd.DataFrame()

def get_digits(text):
    return "".join(re.findall(r'\d+', str(text))) if text else ""

@st.cache_resource
def init_resources():
    # 1. AI ëª¨ë¸ ë¡œë“œ (Hybrid: ResNet50 + DINOv2)
    model_res = ResNet50(weights='imagenet', include_top=False, pooling='avg')
    model_dino = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')
    model_dino.eval()
    
    # 2. ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ
    with open('material_features.pkl', 'rb') as f:
        feature_db = pickle.load(f)
        
    df_path = load_csv_smart('ì´ë¯¸ì§€ê²½ë¡œ.csv')
    df_info = load_csv_smart('í’ˆëª©ì •ë³´.csv')
    df_stock = load_csv_smart('í˜„ì¬ê³ .csv')
    
    # 3. [v2.6 ì´ì‹] ì •ë°€ ì¬ê³  ë§¤ì¹­ ë¡œì§
    agg_stock, stock_date = {}, "í™•ì¸ë¶ˆê°€"
    if not df_stock.empty:
        # ê·œì¹™: ì½¤ë§ˆ ì œê±° ë° ìˆ«ìí™”
        df_stock['ì¬ê³ ìˆ˜ëŸ‰'] = pd.to_numeric(df_stock['ì¬ê³ ìˆ˜ëŸ‰'].astype(str).str.replace(',', ''), errors='coerce').fillna(0)
        # ê·œì¹™: astype(str).strip().upper() ì™„ë²½ í‚¤ ìƒì„±
        df_stock['í’ˆë²ˆ_KEY'] = df_stock['í’ˆë²ˆ'].astype(str).str.strip().str.upper()
        # ê·œì¹™: ì¤‘ë³µ í’ˆë²ˆ í•©ì‚°
        agg_stock = df_stock.groupby('í’ˆë²ˆ_KEY')['ì¬ê³ ìˆ˜ëŸ‰'].sum().to_dict()
        if 'ì •ì‚°ì¼ì' in df_stock.columns:
            stock_date = str(int(df_stock['ì •ì‚°ì¼ì'].max()))
            
    return model_res, model_dino, feature_db, df_path, df_info, agg_stock, stock_date

res_model, dino_model, feature_db, df_path, df_info, agg_stock, stock_date = init_resources()

# --- [2] ì´ë¯¸ì§€ ì²˜ë¦¬ ì—”ì§„ (Advanced Corrections) ---
def apply_advanced_correction(img, angle, bri, con, shp, sat, temp, exp, hue):
    """ì‚¬ìš©ì ìš”ì²­ 5ëŒ€ ë³´ì • ì˜µì…˜ ë° íšŒì „ ê¸°ëŠ¥"""
    # íšŒì „
    if angle != 0: img = img.rotate(angle, expand=True)
    # ê¸°ë³¸ í•„í„°
    img = ImageEnhance.Brightness(img).enhance(bri)
    img = ImageEnhance.Contrast(img).enhance(con)
    img = ImageEnhance.Sharpness(img).enhance(shp)
    img = ImageEnhance.Color(img).enhance(sat)
    # ë…¸ì¶œ ë° ìƒ‰ì˜¨ë„ (Numpy)
    img_np = np.array(img).astype(np.float32)
    img_np *= exp # ë…¸ì¶œ
    if temp > 1.0: img_np[:,:,0] *= temp; img_np[:,:,2] /= temp # Warm
    elif temp < 1.0: img_np[:,:,2] *= (2.0-temp); img_np[:,:,0] /= (2.0-temp) # Cool
    img_np = np.clip(img_np, 0, 255).astype(np.uint8)
    # ìƒ‰ì¡° (HSV)
    if hue != 0:
        hsv = cv2.cvtColor(img_np, cv2.COLOR_RGB2HSV).astype(np.float32)
        hsv[:,:,0] = (hsv[:,:,0] + hue) % 180
        img_np = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2RGB)
    return Image.fromarray(img_np)

def four_point_transform(image, pts):
    """LANCZOS4 ê³ í™”ì§ˆ ì›Œí•‘"""
    rect = np.zeros((4, 2), dtype="float32")
    s = pts.sum(axis=1); rect[0] = pts[np.argmin(s)]; rect[2] = pts[np.argmax(s)]
    diff = np.diff(pts, axis=1); rect[1] = pts[np.argmin(diff)]; rect[3] = pts[np.argmax(diff)]
    (tl, tr, br, bl) = rect
    w = max(int(np.sqrt(((br[0]-bl[0])**2)+((br[1]-bl[1])**2))), int(np.sqrt(((tr[0]-tl[0])**2)+((tr[1]-tl[1])**2))))
    h = max(int(np.sqrt(((tr[0]-br[0])**2)+((tr[1]-br[1])**2))), int(np.sqrt(((tl[0]-bl[0])**2)+((tl[1]-bl[1])**2))))
    dst = np.array([[0,0],[w-1,0],[w-1,h-1],[0,h-1]], dtype="float32")
    M = cv2.getPerspectiveTransform(rect, dst)
    return cv2.warpPerspective(image, M, (w, h), flags=cv2.INTER_LANCZOS4)

# --- [3] DecoMatch UI & Branding ---
st.set_page_config(layout="wide", page_title="DecoMatch - Schattdecor")

# Schattdecor í…Œë§ˆ ì ìš©
st.markdown("""
    <style>
    .main { background-color: #f8f9fa; }
    .stButton>button { background-color: #B67741; color: white; border-radius: 4px; border: none; }
    .stExpander { border: 1px solid #B67741; border-radius: 5px; background-color: white; }
    h1 { color: #B67741; font-family: 'Arial Black', sans-serif; }
    </style>
    """, unsafe_allow_value=True)

col_logo, col_title = st.columns([1, 5])
with col_logo:
    st.image("https://brandfetch.com/schattdecor.com?view=library", width=120)
with col_title:
    st.title("DecoMatch")
    st.caption("Advanced Hybrid Surface Pattern Recognition")

st.sidebar.markdown(f"ğŸ“¦ **ì¬ê³  ì •ì‚°ì¼:** \n{stock_date}")

if 'points' not in st.session_state: st.session_state['points'] = []
if 'search_done' not in st.session_state: st.session_state['search_done'] = False
if 'refresh_count' not in st.session_state: st.session_state['refresh_count'] = 0

uploaded = st.file_uploader("ğŸ“· ìì¬ ì‚¬ì§„ ì—…ë¡œë“œ (Upload Material Image)", type=['jpg','png','jpeg'])

if uploaded:
    if 'current_img_name' not in st.session_state or st.session_state['current_img_name'] != uploaded.name:
        st.session_state.update({'points': [], 'search_done': False, 'current_img_name': uploaded.name, 'proc_img': Image.open(uploaded).convert('RGB')})
        st.rerun()

    working_img = st.session_state['proc_img']
    w, h = working_img.size

    # ê³ ê¸‰ ì˜µì…˜ Expander
    with st.expander("ğŸ› ï¸ ê³ ê¸‰ ì´ë¯¸ì§€ ë³´ì • ë° ì‚¬ì§„ íšŒì „ (Advanced Settings)", expanded=False):
        c1, c2, c3 = st.columns(3)
        with c1:
            angle = st.slider("ì‚¬ì§„ íšŒì „ (Rotation)", 0, 360, 0)
            bri = st.slider("ë°ê¸° (Brightness)", 0.5, 2.0, 1.0)
            con = st.slider("ëŒ€ë¹„ (Contrast)", 0.5, 2.0, 1.0)
        with c2:
            shp = st.slider("ì„ ëª…ë„ (Sharpness)", 0.0, 3.0, 1.5)
            sat = st.slider("ì±„ë„ (Saturation)", 0.0, 2.0, 1.0)
            exp = st.slider("ë…¸ì¶œ (Exposure)", 0.5, 2.0, 1.0)
        with c3:
            temp = st.slider("ìƒ‰ì˜¨ë„ (Color Temp)", 0.5, 1.5, 1.0)
            hue = st.slider("ìƒ‰ì¡° (Hue Shift)", 0, 180, 0)
            if st.button("ğŸ”„ ì  ì „ì²´ ì´ˆê¸°í™”"): st.session_state['points'] = []; st.rerun()

    # ì˜ì—­ ì§€ì • ë° ë³´ê¸° í¬ê¸° ì œì–´
    scale = st.radio("ğŸ” ë³´ê¸° í¬ê¸° (View Scale):", [0.1, 0.3, 0.5, 0.7, 1.0], index=2, horizontal=True)
    
    col_ui, col_pad = st.columns([1, 2])
    with col_ui:
        source_type = st.radio("ì›ë³¸ êµ¬ë¶„", ['ğŸ“¸ í˜„ì¥ ì‚¬ì§„', 'ğŸ’» ë””ì§€í„¸ íŒŒì¼'], horizontal=True)
        mat_type = st.selectbox("ğŸ§± ìì¬ ì¢…ë¥˜", ['ì¼ë°˜', 'ë§ˆë£¨/ìš°ë“œ (Wood)', 'í•˜ì´ê·¸ë¡œì‹œ/ìœ ê´‘ (Glossy)', 'ë²½ì§€/íŒ¨ë¸Œë¦­ (Texture)', 'ì„ì¬/ì½˜í¬ë¦¬íŠ¸ (Stone)'])
        s_mode = st.radio("ê²€ìƒ‰ ëª¨ë“œ", ["ì¢…í•©(ì»¬ëŸ¬+íŒ¨í„´)", "íŒ¨í„´ ì¤‘ì‹¬(í‘ë°±)"], horizontal=True)
        if st.button("ğŸ”„ ì´ë¯¸ì§€ ì•ˆë‚˜ì˜´ (ìƒˆë¡œê³ ì¹¨)"): st.session_state['refresh_count'] += 1; st.rerun()

    with col_pad:
        d_img = working_img.resize((int(w*scale), int(h*scale)), Image.Resampling.LANCZOS)
        draw = ImageDraw.Draw(d_img)
        # ì  ì‹œê°í™” ë° ìˆ«ì ë¶€ì—¬
        for i, p in enumerate(st.session_state['points']):
            px, py = p[0]*scale, p[1]*scale
            draw.ellipse((px-8, py-8, px+8, py+8), fill='#B67741', outline='white', width=2)
            draw.text((px+10, py-10), str(i+1), fill='red')
        # 4ì  ê°€ì´ë“œë¼ì¸
        if len(st.session_state['points']) == 4:
            draw.polygon([tuple((p[0]*scale, p[1]*scale)) for p in st.session_state['points']], outline='#00FF00', width=3)

        coords = streamlit_image_coordinates(d_img, key=f"deco_{st.session_state['refresh_count']}")
        if coords and len(st.session_state['points']) < 4:
            new_p = (coords['x']/scale, coords['y']/scale)
            if not st.session_state['points'] or st.session_state['points'][-1] != new_p:
                st.session_state['points'].append(new_p); st.rerun()

    if len(st.session_state['points']) == 4:
        warped = four_point_transform(np.array(working_img), np.array(st.session_state['points'], dtype="float32"))
        final_img = Image.fromarray(warped)
        final_img = apply_advanced_correction(final_img, angle, bri, con, shp, sat, temp, exp, hue)
        if s_mode == "íŒ¨í„´ ì¤‘ì‹¬(í‘ë°±)": final_img = final_img.convert("L").convert("RGB")
        
        st.image(final_img, width=300, caption="DecoMatch Analysis Target")
        
        if st.button("ğŸ” Run DecoMatch Search", type="primary", use_container_width=True):
            with st.spinner('ResNet(ê²° 60%) + DINO(êµ¬ì¡° 40%) í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì¤‘...'):
                # íŠ¹ì§• ì¶”ì¶œ
                x_res = k_image.img_to_array(final_img.resize((224, 224)))
                q_res = res_model.predict(preprocess_input(np.expand_dims(x_res, axis=0)), verbose=0).flatten()
                d_in = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14').eval() # ì¼ì‹œ ë¡œë“œ ë°©ì§€ ìœ„í•´ ìºì‹± í™œìš© ê¶Œì¥
                d_in = T.Compose([T.Resize(224), T.CenterCrop(224), T.ToTensor(), T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])])(final_img).unsqueeze(0)
                with torch.no_grad(): q_dino = dino_model(d_in).cpu().numpy().flatten()

                # [v2.6 ì´ì‹] ì •ë°€ ë§¤ì¹­ ë° ìˆœìœ„ ì‚°ì¶œ
                results = []
                for fn, db_vec in feature_db.items():
                    s_res = cosine_similarity([q_res], [db_vec[:2048]])[0][0]
                    s_dino = cosine_similarity([q_dino], [db_vec[2048:]])[0][0]
                    score = (s_res * 0.6) + (s_dino * 0.4)
                    
                    d_key = get_digits(fn)
                    # í’ˆëª© ë§ˆìŠ¤í„° ë§µ ì—°ë™
                    match_info = df_info[df_info['ìƒí’ˆì½”ë“œ'].apply(get_digits) == d_key]
                    f_code = match_info.iloc[0]['ìƒí’ˆì½”ë“œ'] if not match_info.empty else fn.split('.')[0]
                    
                    # [v2.6 í•µì‹¬] strip().upper() ì¬ê³  ì¡°íšŒ
                    f_key = str(f_code).strip().upper()
                    qty = agg_stock.get(f_key, 0)
                    
                    url_row = df_path[df_path['ì¶”ì¶œëœ_í’ˆë²ˆ'].apply(get_digits) == d_key]
                    url = url_row['ì¹´ì¹´ì˜¤í†¡_ì „ì†¡ìš©_URL'].values[0] if not url_row.empty else None
                    
                    if url:
                        results.append({'formal': f_code, 'name': match_info.iloc[0]['ìƒí’ˆëª…'] if not match_info.empty else "ì •ë³´ì—†ìŒ", 'score': score, 'url': url, 'stock': qty})

                results.sort(key=lambda x: x['score'], reverse=True)
                st.session_state['search_results'] = results[:15]
                st.session_state['search_done'] = True; st.rerun()

# --- [4] ê²°ê³¼ ì¶œë ¥ (Ranked & Expandable) ---
if st.session_state.get('search_done'):
    st.markdown("---")
    st.subheader("ğŸ† DecoMatch Ranking (Top 15)")
    res = st.session_state['search_results']
    cols = st.columns(5)
    for i, item in enumerate(res):
        with cols[i % 5]:
            # ì¹´ë“œ í—¤ë” (ìˆœìœ„ ë° í’ˆë²ˆ)
            st.markdown(f"#### Rank {i+1}")
            st.markdown(f"**{item['formal']}**")
            st.caption(f"Similarity: {item['score']:.1%}")
            
            # ê²°ê³¼ ì´ë¯¸ì§€ ì ‘ê¸°/í¼ì¹˜ê¸°
            with st.expander("ğŸ–¼ï¸ ì´ë¯¸ì§€/ìƒì„¸ ì •ë³´", expanded=False):
                # êµ¬ê¸€ ìš°íšŒ ì¶œë ¥
                b64_img = get_image_as_base64(item['url'])
                if b64_img: st.image(b64_img, use_container_width=True)
                else: st.warning("ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨")
                st.write(f"**í’ˆëª…:** {item['name']}")
                # ì¬ê³  í‘œì‹œ
                if item['stock'] >= 100: st.success(f"í˜„ì¬ê³ : {item['stock']:,}m")
                else: st.info(f"í˜„ì¬ê³ : {item['stock']:,}m")
